{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: to scrape normal transaction from the given link\n",
    "> Link: https://bscscan.com/txs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.common.desired_capabilities import DesiredCapabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to launch browser and get a given link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_chrome(link):\n",
    "    ops = Options()\n",
    "    ops.add_experimental_option(\"detach\", True) # prevents browser from closing when function is returned\n",
    "    # dc = DesiredCapabilities.CHROME\n",
    "    driver = webdriver.Chrome(options=ops,\n",
    "                              executable_path=\"C:/Users/Jay/Desktop/cODE/WebDrivers/chromedriver.exe\")\n",
    "\n",
    "    driver.get(link)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "XPATHs of table rows 1 to 3:\n",
    "\n",
    "   <tr> 1 of <tbody> : \"//*[@id=\"paywall_mask\"]/table/tbody/tr[1]\"\n",
    "\n",
    "   <tr> 2 of <tbody> : \"//*[@id=\"paywall_mask\"]/table/tbody/tr[2]\"\n",
    "\n",
    "   <tr> 3 of <tbody> : \"//*[@id=\"paywall_mask\"]/table/tbody/tr[3]\"\n",
    "\n",
    "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "<td> 3 of <tr> 1 : //*[@id=\"paywall_mask\"]/table/tbody/tr[3]/td[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get headers (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list\n",
    "def get_header(table):\n",
    "    header_txt = table.find_element(By.XPATH, '//*[@id=\"paywall_mask\"]/table/thead').text\n",
    "    temp = header_txt.split(sep='\\n')\n",
    "    # print(temp)\n",
    "    temp2 = temp[0].split(' ')\n",
    "    # print(temp2)\n",
    "    header = [temp2[0]+' '+temp2[1]]\n",
    "    header.append(temp2[2])\n",
    "    header.extend(temp[1:])\n",
    "    return header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to write rows into 'data.csv'\n",
    "```\n",
    "params: \n",
    "   wr: writer object,  \n",
    "   table: table element found using driver.find_element()\n",
    "\n",
    "return:\n",
    "    failed_rows: list\n",
    "    normal_rows: list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: \n",
    "#   wr: writer object,  \n",
    "#   table: table element found using driver.find_element()\n",
    "\n",
    "def write_normal_rows(wr, table):\n",
    "    failed_rows = []\n",
    "    normal_rows = []\n",
    "    # get rows of current page\n",
    "    for row_num in range(1,51):\n",
    "        row_xpath = f'//*[@id=\"paywall_mask\"]/table/tbody/tr[{row_num}]'\n",
    "        #             //*[@id=\"paywall_mask\"]/table/tbody/tr[1]\n",
    "        row = table.find_element(By.XPATH, row_xpath)\n",
    "        # 12 <td> tags in a row\n",
    "        normal_row_content = []\n",
    "        failed_row_content = []\n",
    "\n",
    "        # check if row has span with failed icon (<i> tag)\n",
    "        normal = False\n",
    "        try:\n",
    "            i_xpath = f'//*[@id=\"paywall_mask\"]/table/tbody/tr[{row_num}]/td[2]/span[1]/strong/i'\n",
    "            i_tag = table.find_element(By.XPATH, i_xpath).tag_name\n",
    "\n",
    "        # if failed icon or <i> tag is not found, Then exception will be raised\n",
    "        # it means that transaction is normal\n",
    "        except:\n",
    "            normal = True\n",
    "\n",
    "        # get text from <td> in the row:\n",
    "        # <td> 1, 5, 8, 12 donot have any text\n",
    "        for td_num in [2,3,4,6,7,9,10,11]:   \n",
    "            td_xpath = f'//*[@id=\"paywall_mask\"]/table/tbody/tr[{row_num}]/td[{td_num}]'    \n",
    "            if normal:\n",
    "                normal_row_content.append(row.find_element(By.XPATH, td_xpath).text)\n",
    "\n",
    "            else:\n",
    "                failed_row_content.append(row.find_element(By.XPATH, td_xpath).text)\n",
    "\n",
    "        if len(failed_row_content) > 0:\n",
    "            failed_rows.append(failed_row_content)\n",
    "\n",
    "        normal_rows.append(normal_row_content)\n",
    "        wr.writerow(normal_row_content)\n",
    "\n",
    "\n",
    "    return normal_rows, failed_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get all the transactions\n",
    "`it writes transactions into data.csv and failed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions():\n",
    "    \n",
    "    with open('data.csv', 'w', newline='') as csvfile:\n",
    "        wr = csv.writer(csvfile)\n",
    "\n",
    "        failed_rows = []\n",
    "\n",
    "        driver = launch_chrome(f\"https://bscscan.com/txs\")\n",
    "\n",
    "        table_xpath = '//*[@id=\"paywall_mask\"]/table'\n",
    "        table = driver.find_element(By.XPATH, table_xpath)\n",
    "\n",
    "        header = get_header(table)\n",
    "        wr.writerow(header) # write the header into csv file\n",
    "        print('Writing header to \"data.csv\" file ',header)\n",
    "\n",
    "        for page in range(1,11):\n",
    "\n",
    "            driver = launch_chrome(f\"https://bscscan.com/txs?p={page}\")\n",
    "\n",
    "            print(f\"Reading page{page}...\")\n",
    "\n",
    "\n",
    "            # write rows into csv file and \n",
    "            # return lists of normal_rows, failed_rows\n",
    "            normal_rows, failed_rows = write_normal_rows(wr, table)\n",
    "             \n",
    "            # print(failed_rows)\n",
    "            # write failed rows in its csv file\n",
    "\n",
    "            # click next to go to next page\n",
    "            next = driver.find_element(By.XPATH,'//*[@id=\"ctl00\"]/div[3]/ul/li[4]/a')\n",
    "            next.click()\n",
    "\n",
    "            driver.quit() # close driver\n",
    "\n",
    "    print('Successfully written all normal rows into \"data.csv\" ')\n",
    "    with open('failed_data.csv', 'w', newline='') as csvfile:\n",
    "        wr = csv.writer(csvfile)\n",
    "        wr.writerow(header) # write the header into csv file\n",
    "        print('Writing header to \\'failed_data.csv\\' file ',header)\n",
    "\n",
    "        print(\"Writing failed rows into the csv file...\")\n",
    "        [ wr.writerow(fr) for fr in failed_rows ]    \n",
    "\n",
    "    print('Successfully written all failed rows into \"failed_data.csv\" ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get 50 transactions from a page scrape 10 such pages total 500 transactions \n",
    "\n",
    "Note: actual number of transactions will be less than 500 as some of them will be in failed_data.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-58a148e52162>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(options=ops,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing header to \"data.csv\" file  ['Txn Hash', 'Method', 'Block', 'Age', 'From', 'To', 'Value', 'Txn Fee']\n",
      "Reading page1...\n",
      "Reading page2...\n",
      "Reading page3...\n",
      "Reading page4...\n",
      "Reading page5...\n",
      "Reading page6...\n",
      "Reading page7...\n",
      "Reading page8...\n",
      "Reading page9...\n",
      "Reading page10...\n",
      "Successfully written all normal rows into \"data.csv\" \n",
      "Writing header to 'failed_data.csv' file  ['Txn Hash', 'Method', 'Block', 'Age', 'From', 'To', 'Value', 'Txn Fee']\n",
      "Writing failed rows into the csv file...\n",
      "Successfully written all failed rows into \"failed_data.csv\" \n"
     ]
    }
   ],
   "source": [
    "get_transactions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a CSV to JSON\n",
    "# Takes the file paths as arguments\n",
    "def make_json(csvFilePath, jsonFilePath):\n",
    "\n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "\n",
    "    # Open a csv reader called DictReader\n",
    "    with open(csvFilePath, encoding='utf-8') as csvf:\n",
    "        csvReader = csv.DictReader(csvf)\n",
    "\n",
    "        # Convert each row into a dictionary\n",
    "        # and add it to data\n",
    "        for rows in csvReader:\n",
    "        \n",
    "            # Assuming a column named 'No' to\n",
    "            # be the primary key\n",
    "            key = rows['Txn Hash']\n",
    "            data[key] = rows\n",
    "\n",
    "    # Open a json writer, and use the json.dumps()\n",
    "    # function to dump data\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf:\n",
    "        jsonf.write(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_json('data.csv', 'data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_json('failed_data.csv', 'failed_data.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "07d623e3832b78ce69fa2c095939a54ed4f3e8fe6909ed4ae68f2da80f027625"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
